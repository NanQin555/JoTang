{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295e33ea",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0c66ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 导入所用的包\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn,optim\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 导入所用的包\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb27f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01731fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 打印数据的描述部分\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310ae13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 打印数据，可直观观察到data 和 target数组\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f522b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二八比例拆分训练集和测试集\n",
    "input, x_test, label, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69832bd9",
   "metadata": {},
   "source": [
    "Tensor(张量)：可以运行在gpu上的多维数据~~而已~~\n",
    "\n",
    "torch.Size本质上是tuple元组，支持tuple的一切操作，元组一旦创建后不能被修改，起到保护数据的作用，可用于固定搭配的场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据张量化\n",
    "input = torch.FloatTensor(input)\n",
    "label = torch.LongTensor(label)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc0293",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_size = int(np.array(label.size()))  # torch数组->numpy数组->数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548fa1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(label.size())\n",
    "print(np.array(label.size()))\n",
    "print(label_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06febe4f",
   "metadata": {},
   "source": [
    "# 神经网络搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf636f",
   "metadata": {},
   "source": [
    "搭建神经网络 它有着**两个隐藏层**,**一个输出层**\n",
    "\n",
    "填写各层**输入输出参数**以及**激活函数**\n",
    "\n",
    "两个隐藏层均使用**线性模型和relu激活函数** 输出层使用**softmax函数**(dim参数设为1)\n",
    "\n",
    "Softmax函数：\n",
    "\n",
    "定义：该元素的指数，与所有元素指数和的比值\n",
    "\n",
    "作用：将多个神经元的输出，映射到（0,1）区间内，概率归一化，从而进行多分类。选择概率大的值，但并不意味着只选择真实值大的值，从而更具有统计意义的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224896cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NET(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden1,n_hidden2, n_output):\n",
    "        super(NET, self).__init__()\n",
    "        self.hidden1 = nn.Linear(n_feature, n_hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    " \n",
    "        self.hidden2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    " \n",
    "        self.out = nn.Linear(n_hidden2, n_output)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "#前向传播函数\n",
    "    def forward(self, x):\n",
    "        hidden1 = self.hidden1(x)\n",
    "        relu1 = self.relu1(hidden1)\n",
    "#完善代码:\n",
    "        hidden2 = self.hidden1(x)\n",
    "        relu2 = self.relu1(hidden2)\n",
    " \n",
    "        out = relu2\n",
    " \n",
    "        return out\n",
    "#测试函数\n",
    "    def test(self, x):\n",
    "        y_pred = self.forward(x)\n",
    "        y_predict = self.softmax(y_pred)\n",
    " \n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bf1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构以及损失函数\n",
    "#完善代码:根据这个数据集的特点合理补充参数,可设置第二个隐藏层输入输出的特征数均为20\n",
    "net = NET(n_feature=4, n_hidden1=20, n_hidden2=20, n_output=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed83d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#选一个你喜欢的优化器\n",
    "#举个例子 SGD优化器 optimizer = torch.optim.SGD(net.parameters(),lr = 0.02)  # lr 表示学习率\n",
    "#完善代码:我们替你选择了adam优化器,请补充一行代码\n",
    "# adam是高级梯度下降算法\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这是一个交叉熵损失函数,不懂它没关系(^_^)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360df264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#完善代码:请设置一个训练次数的变量(这个神经网络需要训练2000次)\n",
    "time = 2000\n",
    "# 训练网络\n",
    "#完善代码:把参数补充完整\n",
    "for epoch in range(time):\n",
    "    cost = 0\n",
    "#完善代码:利用forward和损失函数获得out(输出)和loss(损失)\n",
    "    out = net(input)\n",
    "    loss = loss_func(out, label)\n",
    "#请在下一行注释中回答zero_grad这一行的作用\n",
    "#调用backward()函数之前都要将梯度清零，如果梯度不清零，pytorch中会将上次计算的梯度和本次计算的梯度累加。\n",
    "    optimizer.zero_grad()\n",
    "#完善代码:反向传播 并更新所有参数\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cost = cost + loss.cpu().detach().numpy()\n",
    "    costs.append(cost / label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7993e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#可视化\n",
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6acca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 测试训练集准确率\n",
    "out = net.test(input)\n",
    "prediction = torch.max(out, 1)[1]\n",
    "pred_y = prediction.numpy()\n",
    "target_y = label.numpy()\n",
    "accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n",
    "print(\"训练集准确率为\", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试测试集准确率\n",
    "out1 = net.test(x_test)\n",
    "prediction1 = torch.max(out1, 1)[1]\n",
    "pred_y1 = prediction1.numpy()\n",
    "target_y1 = y_test.numpy()\n",
    " \n",
    "accuracy1 = float((pred_y1 == target_y1).astype(int).sum()) / float(target_y1.size)\n",
    "print(\"测试集准确率为\", accuracy1 * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c815bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#至此,你已经拥有了一个简易的神经网络,运行一下试试看吧\n",
    "\n",
    "#Q\n",
    "#最后,回答几个简单的问题,本次的问题属于监督学习还是无监督学习呢?batch size又是多大呢?像本题这样的batch size是否适用于大数据集呢,原因是?\n",
    "\n",
    "#A\n",
    "# 监督学习\n",
    "# batch size = none 即一次把所有数据“投喂”\n",
    "# 不适用于大数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
